# stack-trace-classifier
Stack-Trace Classifier is a project that aims to shed additional light on stack-trace exception dumps. A classic exception might look something like

```	
com.google.moneta.api2.common.error.ApiException: <eye3-ignored title='moneta.purchaseorder.service.purchaseorder.purchaseorderinternal.ProxyChargeResponsePb.Error.ERROR_ORDER_NOT_CHARGED'/>  moneta.purchaseorder.service.purchaseorder.purchaseorderinternal.ProxyChargeResponsePb.Error.ERROR_ORDER_NOT_CHARGED
Underlying ApiErrors are: 
	moneta.purchaseorder.service.purchaseorder.purchaseorderinternal.ProxyChargeResponsePb.Error.ERROR_ORDER_NOT_CHARGED
	at com.google.moneta.purchaseorder.service.purchaseorder.purchaseorderinternal.ProxyChargeAction.execute(ProxyChargeAction.java:97)
	at com.google.moneta.purchaseorder.service.purchaseorder.purchaseorderinternal.ProxyChargeAction$$FastClassByCGLIB$$bd6cec39.invoke(<generated>)
	at com.google.apps.framework.inject.methodinvocation.DefaultMethodStateManager.invoke(DefaultMethodStateManager.java:20)
	at com.google.apps.framework.inject.MethodExecutor.execute(MethodExecutor.java:211)
	at com.google.apps.framework.request.impl.InterceptorInvocation.proceed(InterceptorInvocation.java:203)
	at com.google.moneta.api2.framework.common.ActionInvokerInterceptor$InvokeAppsFrameworkActionByReturningControlToAppsFramework.call(ActionInvokerInterceptor.java:58)
	at com.google.moneta.api2.framework.common.ActionInvokerInterceptor$InvokeAppsFrameworkActionByReturningControlToAppsFramework.call(ActionInvokerInterceptor.java:53)
    ...
```

Needless to say, this is quite verbose and for a engineer looking to quickly identify the error, can be quite daunting. 

The purpose of the Stack Trace Classifier is to simplify this task by parsing the stack trace and retrieving a human-readable message. Finally, Stack Trace Classifier clusters the error messages so as to avoid repetitive error messages.

Steps to run stack-trace classifier
Either

1. Create a python virtual environment https://docs.python.org/3/library/venv.html
2. pip3 -r requirements.txt
3. python3 stack_trace_classifier_main.py --config=config_file.textproto (--big_query_config=bq_config_file.textproto)

Or using bazel

1. Ensure bazel is installed https://bazel.build/
2. Run bazel build //python:stack-trace-classifier-main
3. Navigate to bazel-bin
4. ./stack-trace-classifier-main --config=config_file.textproto (--bigquery_config=bq_config_file.textproto)

Note: bazel currently has a strange issue with the google bigquery package installing its own version of six (1.12) even though bigquery requires six version 1.13+, a current work around is to simply delete the generated six directory (and keep the one generated by pip3). Hopefully this won't be an issue with plx as well.

For sample input/output, please first request Donghan for access to the BigQuery project 'payments-purchaseorder' and follow the links as below:
sample input: https://pantheon.corp.google.com/bigquery?project=payments-purchaseorder&p=payments-purchaseorder&d=debuginfo&t=test4&page=table
sample output: https://pantheon.corp.google.com/bigquery?project=payments-purchaseorder&p=payments-purchaseorder&d=debuginfo&t=test4_summary2&page=table

# Classification Methodology
1. We first pattern match to a specific set of 'already known' ERROR_CODES and filter our table based on this.
2. Next, for the remaining exceptions, we first process to remove extraneous information
	* We remove any line that begins with '\tat' since java exception convention generates these lines that provide nothing human readable in the sense of trying to cluster errors. 
	* We remove any line that begins with 'Suppressed:' for the same reason as above
	* We match to only lines that contain at least one ':' since as per java convention, additional human provided error messages when exceptions are thrown are generated in the format of 'errorType: error message'
3. Next, we tokenize our input through various rules
	* We perform a preemptive tokenize using new lines and spaces package
	* We filter out all single character tokens as these are usually either punctuations or negligible words like 'a'
	* We split on '=' since often error messages contain embedded data types
	* We remove all trailing and leading punctuation
	* We filter out all hex numerals and decimal numerals since these are often ip addresses, version numbers and processIds.
	* We remove all words not in the english dictionary
4. Finally, we perform K-Means clustering on the remaining datapoints using Cosine Term Frequency. We used Cosine Term Frequency rather than Raw Term Frequency since error messages often repeated themselves variable numbers of times. I.E. "Transaction id:1111 failed because of cancellation ... Transaction id:1111 failed because of cancellation" should be grouped together with "Transaction id:1234 failed because of cancellation".